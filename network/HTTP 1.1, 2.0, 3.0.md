## HTTP 1.0 -> HTTP 1.1의 가장 큰 변화

- persistant connection: 요청을 보내고 응답을 받으면 TCP connection을 끊는게 아니라 특정 시간동안 유지, 해당 세션으로 계속 요청과 응답을 주고받을 수 있음

> 매번 새로운 요청마다 3 way handshake 과정을 수행하지 않아도 됨
> 
- 번외: TCP는 UDP와 달리 3 way handshake가 필요한 이유
    
    일단 양측이 서로 데이터를 주고받을 준비가 되었다는 걸 알리는 과정이기도 하고, 이때 양측이 서로의 **초기 sequence number를 교환**
    
    초기 sequence number는 0-2^31-1 사이의 랜덤한 번호를 배정하기 때문에, 전송측과 수신측이 이를 3 way handshake 과정에서 서로 교환해야 알 수 있음
    
    > 랜덤한 번호를 선택하는 이유는 이전 커넥션의 패킷과 쉽게 구분하기 위함도 있고, 보안을 위해서
    https://en.wikipedia.org/wiki/TCP_sequence_prediction_attack
    > 
    
- pipelining: 요청 -> 응답을 serial하게 할 필요 없이 응답을 기다리지 않고 계속 요청을 보낼 수 있음

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*o4Rj35BFDHRtHHz1.png)

> 그러나 응답을 순서에 관계없이 받을 수 있는 완전한 비동기 방식은 아님(non-blocking synchronous 방식)
> 
> 
> 기본적으로 각 응답이 어느 요청에 대응하는지 명확히 구분하기 위해(응답 순서가 뒤바뀌면 수신측 입장에선 각 응답이 어느 요청에 대한 응답인지 헷갈리므로)
> 
> 먼저 들어온 요청에 대한 응답이 먼저 나가는 FIFO 방식으로 구현됨, 따라서 특정 요청에 대한 처리가 완료되어도 이전 요청에 대한 응답이 완료되지 않으면 응답할 수 없는 HOL(Head of Line) blocking 문제가 있음
> 

## HTTP 2.0

- 하나의 커넥션에 동시에 여러 요청을 스트림 단위로 병렬로 전송

> 이때 각 스트림은 HTTP 1.1과 달리 독립적으로 서로의 순서를 지킬 필요가 없음
메시지(요청 혹은 응답의 단위)를 프레임(헤더 혹은 데이터)이라는 더 작은 단위로 분할하여 각 프레임을 서로 다른 스트림으로 전송할 수 있음
> 

![](https://mark-kim.blog/static/c0378d43c56fe6482d421edd37cd2553/b10c1/http_1_1_vs_http_2.webp)

스트림이라는게 어떤 물리적인 통로 개념으로 생각해서 잘 이해가 안되었었는데, 그런게 아니라 **그냥 요청-응답을 매핑하는 매핑 번호(스트림 ID)를 의미**하는 것

스트림 ID가 이 응답이 어떤 요청에 대한 응답인지 알려주기 때문에 전송하는 입장에선 꼭 들어온 요청 순서대로 응답을 보낼 필요 없이 처리가 끝나는 대로 순서에 상관 없이 보낼 수 있게 됨

> 새로 만들어지는 스트림의 식별자는 이전에 만들어졌거나 예약된 스트림들의 식별자보다 커야 한다. 
한번 사용한 스트림 식별자는 다시 사용할 수 없다.
하나의 커넥션에서 오래 스트림을 사용하다보면 스트림에 할당될 수 있는 식별자가 고갈되기도 하는데, 그런 경우 커넥션을 다시 맺는 식으로 처리한다.
> 

그러나 이는 어디까지나 애플리케이션 계층에서 HOL blocking 문제를 해결한 것이지, 전송 계층의 TCP 특성에 따른 세그먼트의 순서보장을 위한 HOL blocking 문제는 해결된 것이 아님

> 스트림 ID를 통해 여러 요청을 하나의 TCP 연결에 다중화 하였지만, 어쨌던 TCP 기반이기 때문에 한 패킷이 손실되면 이후 패킷이 전부 처리가 지연되는 TCP의 특성에 따른 HOL 문제를 해결하진 못함 
(여기서 처리가 지연된다는 것은 decapsulation 과정이 지연되어 상위 계층으로 넘겨주지 못한다는 것)
→ 이를 해결하기 위해선 근본적으로 TCP 대신 다른 프로토콜을 사용해야 하고, 그래서 나온게 HTTP 3.0의 QUIC 프로토콜
> 

- 바이너리 프레임 단위로 통신

HTTP 1.1에선 요청과 응답 메시지를 text로 전송했지만, HTTP 2.0에선 바이너리 프레임으로 인코딩해서 전송

(텍스트(ASCII) 프로토콜 → 바이너리 프로토콜로 진화)
HTTP 헤더와 바디가 바이너리 프레임에 담겨 전송

텍스트 인코딩 문제는 Payload 내부 문제고, 통신 자체는 바이너리 규격으로 해결

HTTP 1.1은 줄 단위로 구분하고 읽는 구조이지만, HTTP 2.0은 각 필드마다 정확한 바이트 수가 고정되어 있으므로 개행 문자 해석이 필요 X

| **구분** | **HTTP/1.1** | **HTTP/2** |
| --- | --- | --- |
| 데이터 표현 | 텍스트 (ASCII 기반) | 바이너리 (raw bytes) |
| 65라는 값 전송 | ‘A’라는 문자 전송 | 0x41 (65) 1바이트 그대로 전송 |
| 중간 서버 입장 | 텍스트 해석 (줄바꿈, 공백 등 의미 있음) | 고정된 바이너리 포맷만 해석 |
- 번외: HTTP 1.1은 왜 Base64 인코딩이 필요했을까?
    
    네트워크에는 서로 다른 시스템이 존재한다. 다양한 버전의 리눅스가 있을 수도, 윈도우나 맥이 있을 수도 있다. 문자열을 바이너리로 바꾸는 작업을 애플리케이션이 운영체제에게 완전히 위임한다면, 문자를 보낼 때 운영체제간 서로 문자열을 바이너리로 바꾸는 방법이 달라 받는 010101을 측에선 송신측이 보낸 “!!”를 “!!”이 아닌 완전히 다른 문자인 “??”로 매핑시킬 수 있다.
    반면, 어떤 charset을 사용하는 시스템이던 모두 동일하게 디코딩을 수행하는 기본 문자 64개로만 인코딩을 수행하면 이러한 문제가 없으므로, 안전하게 전송하기 위해 Base64를 사용한다
    

- 헤더 압축

  HTTP 1.1 에서는 연속적으로 요청되는 HTTP 메세지들에게서 헤더값이 중복되는 부분이 많아 역시 메모리가 낭비되었는데, HTTP 2.0 에서는 이전 Message의 헤더의 내용 중 중복되는 필드를 재전송하지 않도록하여 데이터를 절약

## HTTP 3.0

- TCP 가 아닌 UDP 채택
- QUIC 프로토콜

> 앞서 2.0은 애플리케이션 계층에서의 HOL blocking 문제는 해결했지만 TCP 자체의 순서보장에 따른 HOL blocking 문제는 해결하지 못하였다고 했음,    
> 이를 해결하기 위해 TCP 대신 UDP를 채택     
(TCP는 패킷을 무조건 순서대로 처리, 중간에 패킷이 유실될 시 다시 보내야 함, 이로 인해 병목현상 발생)
> 

![](https://velog.velcdn.com/images%2Fshroad1802%2Fpost%2F9a9d652d-cbbe-4752-835c-5e3c04dd4fc6%2Fimage.png)

TCP는 순서 보장을 위해 **시퀀스 번호**를 사용하는데 만약 중간에 패킷이 손실되면, 수신 측은 연속된 시퀀스 번호에 해당하는 데이터만 상위 애플리케이션에 전달하고 ACK 번호로 해당 유실된 패킷의 시퀀스 번호를 요청하므로
손실된 패킷 이후의 시퀀스 번호를 갖는 패킷들은 애플리케이션 계층에 전달되지 못함

반면 QUIC 프로토콜은 UDP 위에서 동작하지만 TCP와 유사한 패킷 번호 체계를 구현하고 있고  **패킷 번호와 스트림 ID를 활용해** 손실된 부분만 선택적으로 재전송 요청을 하고 다른 스트림에 속한(다른 요청-응답) 패킷은 애플리케이션 계층으로 올려 보냄

> 패킷 손실 시 재전송 단위가 HTTP 2.0 까진 커넥션 단위 → HTTP 3.0에선 스트림 단위     
하나의 스트림에서 패킷 손실 발생해도, 다른 스트림은 **전혀 영향 없이 계속 처리**
> 
- connection ID 라는 개념을 사용하여 두 노드 간 연결 유지, IP 주소가 변경되어도 커넥션을 새로 수립할 필요 없이 기존 커넥션을 사용
- TLS를 통합하여 기본적으로 암호화하여 전송

> 기존 TCP 방식은 TCP 연결을 위한 handshake 과정과 TLS 연결을 위한 handshake 과정을 별도로 진행했는데, QUIC 프로토콜은 이를 통합하여 단축
>
